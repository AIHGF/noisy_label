I1006 11:31:59.925619  3595 caffe.cpp:157] Use GPU with device ID 0
I1006 11:31:59.926724  3595 caffe.cpp:165] Starting Optimization
I1006 11:31:59.926834  3595 solver.cpp:37] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.001
display: 100
max_iter: 6000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.004
stepsize: 4000
snapshot: 8000
snapshot_prefix: "external/exp/models/cifar10_noisy_label_loss"
solver_mode: CPU
net: "models/cifar10_noisy_label_loss_trainval.prototxt"
test_initialization: true
average_loss: 100
I1006 11:31:59.926857  3595 solver.cpp:75] Creating training net from net file: models/cifar10_noisy_label_loss_trainval.prototxt
I1006 11:31:59.927440  3595 net.cpp:307] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1006 11:31:59.927455  3595 net.cpp:307] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1006 11:31:59.927695  3595 net.cpp:46] Initializing net from parameters: 
name: "cifar10_noisy_label_loss"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "external/exp/db/cifar10/cifar10_mean.binaryproto"
  }
  data_param {
    source: "external/exp/db/cifar10/mixed_train_images"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "label_clean"
  type: "Data"
  top: "label_clean"
  include {
    phase: TRAIN
  }
  data_param {
    source: "external/exp/db/cifar10/mixed_train_label_clean"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "label_noisy"
  type: "Data"
  top: "label_noisy"
  include {
    phase: TRAIN
  }
  data_param {
    source: "external/exp/db/cifar10/mixed_train_label_noisy"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "label_ntype"
  type: "Data"
  top: "label_ntype"
  include {
    phase: TRAIN
  }
  data_param {
    source: "external/exp/db/cifar10/mixed_train_label_ntype"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1_clean"
  type: "Convolution"
  bottom: "data"
  top: "conv1_clean"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1_clean"
  type: "Pooling"
  bottom: "conv1_clean"
  top: "pool1_clean"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1_clean"
  type: "ReLU"
  bottom: "pool1_clean"
  top: "pool1_clean"
}
layer {
  name: "conv2_clean"
  type: "Convolution"
  bottom: "pool1_clean"
  top: "conv2_clean"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_clean"
  type: "ReLU"
  bottom: "conv2_clean"
  top: "conv2_clean"
}
layer {
  name: "pool2_clean"
  type: "Pooling"
  bottom: "conv2_clean"
  top: "pool2_clean"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_clean"
  type: "Convolution"
  bottom: "pool2_clean"
  top: "conv3_clean"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_clean"
  type: "ReLU"
  bottom: "conv3_clean"
  top: "conv3_clean"
}
layer {
  name: "pool3_clean"
  type: "Pooling"
  bottom: "conv3_clean"
  top: "pool3_clean"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1_clean"
  type: "InnerProduct"
  bottom: "pool3_clean"
  top: "ip1_clean"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip2_clean"
  type: "InnerProduct"
  bottom: "ip1_clean"
  top: "ip2_clean"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss_clean"
  type: "SoftmaxWithLoss"
  bottom: "ip2_clean"
  bottom: "label_clean"
  top: "loss_clean"
  loss_param {
    ignore_label: -1
    normalize: false
  }
}
layer {
  name: "conv1_ntype"
  type: "Convolution"
  bottom: "data"
  top: "conv1_ntype"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  include {
    phase: TRAIN
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1_ntype"
  type: "Pooling"
  bottom: "conv1_ntype"
  top: "pool1_ntype"
  include {
    phase: TRAIN
  }
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1_ntype"
  type: "ReLU"
  bottom: "pool1_ntype"
  top: "pool1_ntype"
  include {
    phase: TRAIN
  }
}
layer {
  name: "conv2_ntype"
  type: "Convolution"
  bottom: "pool1_ntype"
  top: "conv2_ntype"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  include {
    phase: TRAIN
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_ntype"
  type: "ReLU"
  bottom: "conv2_ntype"
  top: "conv2_ntype"
  include {
    phase: TRAIN
  }
}
layer {
  name: "pool2_ntype"
  type: "Pooling"
  bottom: "conv2_ntype"
  top: "pool2_ntype"
  include {
    phase: TRAIN
  }
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_ntype"
  type: "Convolution"
  bottom: "pool2_ntype"
  top: "conv3_ntype"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  include {
    phase: TRAIN
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_ntype"
  type: "ReLU"
  bottom: "conv3_ntype"
  top: "conv3_ntype"
  include {
    phase: TRAIN
  }
}
layer {
  name: "pool3_ntype"
  type: "Pooling"
  bottom: "conv3_ntype"
  top: "pool3_ntype"
  include {
    phase: TRAIN
  }
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1_ntype"
  type: "InnerProduct"
  bottom: "pool3_ntype"
  top: "ip1_ntype"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  include {
    phase: TRAIN
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip2_ntype"
  type: "InnerProduct"
  bottom: "ip1_ntype"
  top: "ip2_ntype"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  include {
    phase: TRAIN
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss_ntype"
  type: "SoftmaxWithLoss"
  bottom: "ip2_ntype"
  bottom: "label_ntype"
  top: "loss_ntype"
  include {
    phase: TRAIN
  }
  loss_param {
    ignore_label: -1
  }
}
layer {
  name: "loss_noisy"
  type: "SoftmaxWithNoisyLabelLoss"
  bottom: "ip2_clean"
  bottom: "ip2_ntype"
  bottom: "label_noisy"
  top: "loss_noisy"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  softmax_noisy_label_loss_param {
    matrix_c_filler {
      type: "blob_proto"
      source: "external/exp/db/cifar10/matrix_c.binaryproto"
    }
  }
}
I1006 11:31:59.927831  3595 layer_factory.hpp:74] Creating layer cifar
I1006 11:31:59.927845  3595 net.cpp:110] Creating Layer cifar
I1006 11:31:59.927852  3595 net.cpp:388] cifar -> data
I1006 11:31:59.927872  3595 net.cpp:140] Setting up cifar
I1006 11:31:59.927878  3595 data_transformer.cpp:22] Loading mean file from: external/exp/db/cifar10/cifar10_mean.binaryproto
I1006 11:31:59.928012  3595 db_lmdb.cpp:22] Opened lmdb external/exp/db/cifar10/mixed_train_images
I1006 11:31:59.928050  3595 data_layer.cpp:55] Skipping first 0 data points.
I1006 11:31:59.928071  3595 data_layer.cpp:100] output data size: 100,3,32,32
I1006 11:31:59.928154  3595 net.cpp:147] Top shape: 100 3 32 32 (307200)
I1006 11:31:59.928161  3595 layer_factory.hpp:74] Creating layer data_cifar_0_split
I1006 11:31:59.928167  3595 net.cpp:110] Creating Layer data_cifar_0_split
I1006 11:31:59.928184  3595 net.cpp:430] data_cifar_0_split <- data
I1006 11:31:59.928190  3595 net.cpp:388] data_cifar_0_split -> data_cifar_0_split_0
I1006 11:31:59.928196  3595 net.cpp:388] data_cifar_0_split -> data_cifar_0_split_1
I1006 11:31:59.928205  3595 net.cpp:140] Setting up data_cifar_0_split
I1006 11:31:59.928222  3595 net.cpp:147] Top shape: 100 3 32 32 (307200)
I1006 11:31:59.928226  3595 net.cpp:147] Top shape: 100 3 32 32 (307200)
I1006 11:31:59.928230  3595 layer_factory.hpp:74] Creating layer label_clean
I1006 11:31:59.928234  3595 net.cpp:110] Creating Layer label_clean
I1006 11:31:59.928238  3595 net.cpp:388] label_clean -> label_clean
I1006 11:31:59.928244  3595 net.cpp:140] Setting up label_clean
I1006 11:31:59.928302  3595 db_lmdb.cpp:22] Opened lmdb external/exp/db/cifar10/mixed_train_label_clean
I1006 11:31:59.928323  3595 data_layer.cpp:55] Skipping first 0 data points.
I1006 11:31:59.928328  3595 data_layer.cpp:100] output data size: 100,1,1,1
I1006 11:31:59.928375  3595 net.cpp:147] Top shape: 100 1 1 1 (100)
I1006 11:31:59.928380  3595 layer_factory.hpp:74] Creating layer label_noisy
I1006 11:31:59.928397  3595 net.cpp:110] Creating Layer label_noisy
I1006 11:31:59.928402  3595 net.cpp:388] label_noisy -> label_noisy
I1006 11:31:59.928408  3595 net.cpp:140] Setting up label_noisy
I1006 11:31:59.928434  3595 db_lmdb.cpp:22] Opened lmdb external/exp/db/cifar10/mixed_train_label_noisy
I1006 11:31:59.928442  3595 data_layer.cpp:55] Skipping first 0 data points.
I1006 11:31:59.928448  3595 data_layer.cpp:100] output data size: 100,1,1,1
I1006 11:31:59.928472  3595 net.cpp:147] Top shape: 100 1 1 1 (100)
I1006 11:31:59.928478  3595 layer_factory.hpp:74] Creating layer label_ntype
I1006 11:31:59.928483  3595 net.cpp:110] Creating Layer label_ntype
I1006 11:31:59.928488  3595 net.cpp:388] label_ntype -> label_ntype
I1006 11:31:59.928493  3595 net.cpp:140] Setting up label_ntype
I1006 11:31:59.928517  3595 db_lmdb.cpp:22] Opened lmdb external/exp/db/cifar10/mixed_train_label_ntype
I1006 11:31:59.928525  3595 data_layer.cpp:55] Skipping first 0 data points.
I1006 11:31:59.928530  3595 data_layer.cpp:100] output data size: 100,1,1,1
I1006 11:31:59.928550  3595 net.cpp:147] Top shape: 100 1 1 1 (100)
I1006 11:31:59.928553  3595 layer_factory.hpp:74] Creating layer conv1_clean
I1006 11:31:59.928561  3595 net.cpp:110] Creating Layer conv1_clean
I1006 11:31:59.928565  3595 net.cpp:430] conv1_clean <- data_cifar_0_split_0
I1006 11:31:59.928575  3595 net.cpp:388] conv1_clean -> conv1_clean
I1006 11:31:59.928582  3595 net.cpp:140] Setting up conv1_clean
I1006 11:32:00.003465  3595 net.cpp:147] Top shape: 100 32 32 32 (3276800)
I1006 11:32:00.003506  3595 layer_factory.hpp:74] Creating layer pool1_clean
I1006 11:32:00.003520  3595 net.cpp:110] Creating Layer pool1_clean
I1006 11:32:00.003523  3595 net.cpp:430] pool1_clean <- conv1_clean
I1006 11:32:00.003530  3595 net.cpp:388] pool1_clean -> pool1_clean
I1006 11:32:00.003551  3595 net.cpp:140] Setting up pool1_clean
I1006 11:32:00.003677  3595 net.cpp:147] Top shape: 100 32 16 16 (819200)
I1006 11:32:00.003684  3595 layer_factory.hpp:74] Creating layer relu1_clean
I1006 11:32:00.003690  3595 net.cpp:110] Creating Layer relu1_clean
I1006 11:32:00.003693  3595 net.cpp:430] relu1_clean <- pool1_clean
I1006 11:32:00.003697  3595 net.cpp:377] relu1_clean -> pool1_clean (in-place)
I1006 11:32:00.003705  3595 net.cpp:140] Setting up relu1_clean
I1006 11:32:00.003909  3595 net.cpp:147] Top shape: 100 32 16 16 (819200)
I1006 11:32:00.003916  3595 layer_factory.hpp:74] Creating layer conv2_clean
I1006 11:32:00.003927  3595 net.cpp:110] Creating Layer conv2_clean
I1006 11:32:00.003931  3595 net.cpp:430] conv2_clean <- pool1_clean
I1006 11:32:00.003934  3595 net.cpp:388] conv2_clean -> conv2_clean
I1006 11:32:00.003942  3595 net.cpp:140] Setting up conv2_clean
I1006 11:32:00.004673  3595 net.cpp:147] Top shape: 100 32 16 16 (819200)
I1006 11:32:00.004698  3595 layer_factory.hpp:74] Creating layer relu2_clean
I1006 11:32:00.004703  3595 net.cpp:110] Creating Layer relu2_clean
I1006 11:32:00.004706  3595 net.cpp:430] relu2_clean <- conv2_clean
I1006 11:32:00.004710  3595 net.cpp:377] relu2_clean -> conv2_clean (in-place)
I1006 11:32:00.004714  3595 net.cpp:140] Setting up relu2_clean
I1006 11:32:00.004839  3595 net.cpp:147] Top shape: 100 32 16 16 (819200)
I1006 11:32:00.004845  3595 layer_factory.hpp:74] Creating layer pool2_clean
I1006 11:32:00.004863  3595 net.cpp:110] Creating Layer pool2_clean
I1006 11:32:00.004866  3595 net.cpp:430] pool2_clean <- conv2_clean
I1006 11:32:00.004873  3595 net.cpp:388] pool2_clean -> pool2_clean
I1006 11:32:00.004876  3595 net.cpp:140] Setting up pool2_clean
I1006 11:32:00.005112  3595 net.cpp:147] Top shape: 100 32 8 8 (204800)
I1006 11:32:00.005120  3595 layer_factory.hpp:74] Creating layer conv3_clean
I1006 11:32:00.005127  3595 net.cpp:110] Creating Layer conv3_clean
I1006 11:32:00.005131  3595 net.cpp:430] conv3_clean <- pool2_clean
I1006 11:32:00.005136  3595 net.cpp:388] conv3_clean -> conv3_clean
I1006 11:32:00.005141  3595 net.cpp:140] Setting up conv3_clean
I1006 11:32:00.006113  3595 net.cpp:147] Top shape: 100 64 8 8 (409600)
I1006 11:32:00.006124  3595 layer_factory.hpp:74] Creating layer relu3_clean
I1006 11:32:00.006129  3595 net.cpp:110] Creating Layer relu3_clean
I1006 11:32:00.006131  3595 net.cpp:430] relu3_clean <- conv3_clean
I1006 11:32:00.006137  3595 net.cpp:377] relu3_clean -> conv3_clean (in-place)
I1006 11:32:00.006141  3595 net.cpp:140] Setting up relu3_clean
I1006 11:32:00.006278  3595 net.cpp:147] Top shape: 100 64 8 8 (409600)
I1006 11:32:00.006285  3595 layer_factory.hpp:74] Creating layer pool3_clean
I1006 11:32:00.006291  3595 net.cpp:110] Creating Layer pool3_clean
I1006 11:32:00.006294  3595 net.cpp:430] pool3_clean <- conv3_clean
I1006 11:32:00.006297  3595 net.cpp:388] pool3_clean -> pool3_clean
I1006 11:32:00.006302  3595 net.cpp:140] Setting up pool3_clean
I1006 11:32:00.006521  3595 net.cpp:147] Top shape: 100 64 4 4 (102400)
I1006 11:32:00.006528  3595 layer_factory.hpp:74] Creating layer ip1_clean
I1006 11:32:00.006536  3595 net.cpp:110] Creating Layer ip1_clean
I1006 11:32:00.006538  3595 net.cpp:430] ip1_clean <- pool3_clean
I1006 11:32:00.006544  3595 net.cpp:388] ip1_clean -> ip1_clean
I1006 11:32:00.006551  3595 net.cpp:140] Setting up ip1_clean
I1006 11:32:00.007182  3595 net.cpp:147] Top shape: 100 64 (6400)
I1006 11:32:00.007190  3595 layer_factory.hpp:74] Creating layer ip2_clean
I1006 11:32:00.007195  3595 net.cpp:110] Creating Layer ip2_clean
I1006 11:32:00.007199  3595 net.cpp:430] ip2_clean <- ip1_clean
I1006 11:32:00.007205  3595 net.cpp:388] ip2_clean -> ip2_clean
I1006 11:32:00.007210  3595 net.cpp:140] Setting up ip2_clean
I1006 11:32:00.007225  3595 net.cpp:147] Top shape: 100 10 (1000)
I1006 11:32:00.007230  3595 layer_factory.hpp:74] Creating layer ip2_clean_ip2_clean_0_split
I1006 11:32:00.007236  3595 net.cpp:110] Creating Layer ip2_clean_ip2_clean_0_split
I1006 11:32:00.007239  3595 net.cpp:430] ip2_clean_ip2_clean_0_split <- ip2_clean
I1006 11:32:00.007244  3595 net.cpp:388] ip2_clean_ip2_clean_0_split -> ip2_clean_ip2_clean_0_split_0
I1006 11:32:00.007249  3595 net.cpp:388] ip2_clean_ip2_clean_0_split -> ip2_clean_ip2_clean_0_split_1
I1006 11:32:00.007254  3595 net.cpp:140] Setting up ip2_clean_ip2_clean_0_split
I1006 11:32:00.007259  3595 net.cpp:147] Top shape: 100 10 (1000)
I1006 11:32:00.007262  3595 net.cpp:147] Top shape: 100 10 (1000)
I1006 11:32:00.007266  3595 layer_factory.hpp:74] Creating layer loss_clean
I1006 11:32:00.007271  3595 net.cpp:110] Creating Layer loss_clean
I1006 11:32:00.007273  3595 net.cpp:430] loss_clean <- ip2_clean_ip2_clean_0_split_0
I1006 11:32:00.007277  3595 net.cpp:430] loss_clean <- label_clean
I1006 11:32:00.007282  3595 net.cpp:388] loss_clean -> loss_clean
I1006 11:32:00.007288  3595 net.cpp:140] Setting up loss_clean
I1006 11:32:00.007295  3595 layer_factory.hpp:74] Creating layer loss_clean
I1006 11:32:00.007423  3595 net.cpp:147] Top shape: (1)
I1006 11:32:00.007429  3595 net.cpp:149]     with loss weight 1
I1006 11:32:00.007446  3595 layer_factory.hpp:74] Creating layer conv1_ntype
I1006 11:32:00.007467  3595 net.cpp:110] Creating Layer conv1_ntype
I1006 11:32:00.007472  3595 net.cpp:430] conv1_ntype <- data_cifar_0_split_1
I1006 11:32:00.007477  3595 net.cpp:388] conv1_ntype -> conv1_ntype
I1006 11:32:00.007483  3595 net.cpp:140] Setting up conv1_ntype
I1006 11:32:00.008034  3595 net.cpp:147] Top shape: 100 32 32 32 (3276800)
I1006 11:32:00.008044  3595 layer_factory.hpp:74] Creating layer pool1_ntype
I1006 11:32:00.008052  3595 net.cpp:110] Creating Layer pool1_ntype
I1006 11:32:00.008055  3595 net.cpp:430] pool1_ntype <- conv1_ntype
I1006 11:32:00.008059  3595 net.cpp:388] pool1_ntype -> pool1_ntype
I1006 11:32:00.008064  3595 net.cpp:140] Setting up pool1_ntype
I1006 11:32:00.008257  3595 net.cpp:147] Top shape: 100 32 16 16 (819200)
I1006 11:32:00.008265  3595 layer_factory.hpp:74] Creating layer relu1_ntype
I1006 11:32:00.008271  3595 net.cpp:110] Creating Layer relu1_ntype
I1006 11:32:00.008278  3595 net.cpp:430] relu1_ntype <- pool1_ntype
I1006 11:32:00.008285  3595 net.cpp:377] relu1_ntype -> pool1_ntype (in-place)
I1006 11:32:00.008290  3595 net.cpp:140] Setting up relu1_ntype
I1006 11:32:00.008406  3595 net.cpp:147] Top shape: 100 32 16 16 (819200)
I1006 11:32:00.008414  3595 layer_factory.hpp:74] Creating layer conv2_ntype
I1006 11:32:00.008420  3595 net.cpp:110] Creating Layer conv2_ntype
I1006 11:32:00.008424  3595 net.cpp:430] conv2_ntype <- pool1_ntype
I1006 11:32:00.008430  3595 net.cpp:388] conv2_ntype -> conv2_ntype
I1006 11:32:00.008435  3595 net.cpp:140] Setting up conv2_ntype
I1006 11:32:00.009179  3595 net.cpp:147] Top shape: 100 32 16 16 (819200)
I1006 11:32:00.009189  3595 layer_factory.hpp:74] Creating layer relu2_ntype
I1006 11:32:00.009196  3595 net.cpp:110] Creating Layer relu2_ntype
I1006 11:32:00.009201  3595 net.cpp:430] relu2_ntype <- conv2_ntype
I1006 11:32:00.009204  3595 net.cpp:377] relu2_ntype -> conv2_ntype (in-place)
I1006 11:32:00.009208  3595 net.cpp:140] Setting up relu2_ntype
I1006 11:32:00.009323  3595 net.cpp:147] Top shape: 100 32 16 16 (819200)
I1006 11:32:00.009330  3595 layer_factory.hpp:74] Creating layer pool2_ntype
I1006 11:32:00.009335  3595 net.cpp:110] Creating Layer pool2_ntype
I1006 11:32:00.009338  3595 net.cpp:430] pool2_ntype <- conv2_ntype
I1006 11:32:00.009343  3595 net.cpp:388] pool2_ntype -> pool2_ntype
I1006 11:32:00.009348  3595 net.cpp:140] Setting up pool2_ntype
I1006 11:32:00.009543  3595 net.cpp:147] Top shape: 100 32 8 8 (204800)
I1006 11:32:00.009551  3595 layer_factory.hpp:74] Creating layer conv3_ntype
I1006 11:32:00.009558  3595 net.cpp:110] Creating Layer conv3_ntype
I1006 11:32:00.009562  3595 net.cpp:430] conv3_ntype <- pool2_ntype
I1006 11:32:00.009567  3595 net.cpp:388] conv3_ntype -> conv3_ntype
I1006 11:32:00.009572  3595 net.cpp:140] Setting up conv3_ntype
I1006 11:32:00.010553  3595 net.cpp:147] Top shape: 100 64 8 8 (409600)
I1006 11:32:00.010563  3595 layer_factory.hpp:74] Creating layer relu3_ntype
I1006 11:32:00.010570  3595 net.cpp:110] Creating Layer relu3_ntype
I1006 11:32:00.010572  3595 net.cpp:430] relu3_ntype <- conv3_ntype
I1006 11:32:00.010576  3595 net.cpp:377] relu3_ntype -> conv3_ntype (in-place)
I1006 11:32:00.010581  3595 net.cpp:140] Setting up relu3_ntype
I1006 11:32:00.010701  3595 net.cpp:147] Top shape: 100 64 8 8 (409600)
I1006 11:32:00.010709  3595 layer_factory.hpp:74] Creating layer pool3_ntype
I1006 11:32:00.010715  3595 net.cpp:110] Creating Layer pool3_ntype
I1006 11:32:00.010717  3595 net.cpp:430] pool3_ntype <- conv3_ntype
I1006 11:32:00.010722  3595 net.cpp:388] pool3_ntype -> pool3_ntype
I1006 11:32:00.010726  3595 net.cpp:140] Setting up pool3_ntype
I1006 11:32:00.010918  3595 net.cpp:147] Top shape: 100 64 4 4 (102400)
I1006 11:32:00.010926  3595 layer_factory.hpp:74] Creating layer ip1_ntype
I1006 11:32:00.010932  3595 net.cpp:110] Creating Layer ip1_ntype
I1006 11:32:00.010936  3595 net.cpp:430] ip1_ntype <- pool3_ntype
I1006 11:32:00.010941  3595 net.cpp:388] ip1_ntype -> ip1_ntype
I1006 11:32:00.010947  3595 net.cpp:140] Setting up ip1_ntype
I1006 11:32:00.011546  3595 net.cpp:147] Top shape: 100 64 (6400)
I1006 11:32:00.011559  3595 layer_factory.hpp:74] Creating layer ip2_ntype
I1006 11:32:00.011564  3595 net.cpp:110] Creating Layer ip2_ntype
I1006 11:32:00.011567  3595 net.cpp:430] ip2_ntype <- ip1_ntype
I1006 11:32:00.011574  3595 net.cpp:388] ip2_ntype -> ip2_ntype
I1006 11:32:00.011579  3595 net.cpp:140] Setting up ip2_ntype
I1006 11:32:00.011589  3595 net.cpp:147] Top shape: 100 3 (300)
I1006 11:32:00.011595  3595 layer_factory.hpp:74] Creating layer ip2_ntype_ip2_ntype_0_split
I1006 11:32:00.011617  3595 net.cpp:110] Creating Layer ip2_ntype_ip2_ntype_0_split
I1006 11:32:00.011620  3595 net.cpp:430] ip2_ntype_ip2_ntype_0_split <- ip2_ntype
I1006 11:32:00.011626  3595 net.cpp:388] ip2_ntype_ip2_ntype_0_split -> ip2_ntype_ip2_ntype_0_split_0
I1006 11:32:00.011631  3595 net.cpp:388] ip2_ntype_ip2_ntype_0_split -> ip2_ntype_ip2_ntype_0_split_1
I1006 11:32:00.011636  3595 net.cpp:140] Setting up ip2_ntype_ip2_ntype_0_split
I1006 11:32:00.011641  3595 net.cpp:147] Top shape: 100 3 (300)
I1006 11:32:00.011646  3595 net.cpp:147] Top shape: 100 3 (300)
I1006 11:32:00.011661  3595 layer_factory.hpp:74] Creating layer loss_ntype
I1006 11:32:00.011665  3595 net.cpp:110] Creating Layer loss_ntype
I1006 11:32:00.011668  3595 net.cpp:430] loss_ntype <- ip2_ntype_ip2_ntype_0_split_0
I1006 11:32:00.011672  3595 net.cpp:430] loss_ntype <- label_ntype
I1006 11:32:00.011677  3595 net.cpp:388] loss_ntype -> loss_ntype
I1006 11:32:00.011683  3595 net.cpp:140] Setting up loss_ntype
I1006 11:32:00.011688  3595 layer_factory.hpp:74] Creating layer loss_ntype
I1006 11:32:00.011891  3595 net.cpp:147] Top shape: (1)
I1006 11:32:00.011898  3595 net.cpp:149]     with loss weight 1
I1006 11:32:00.011904  3595 layer_factory.hpp:74] Creating layer loss_noisy
I1006 11:32:00.011914  3595 net.cpp:110] Creating Layer loss_noisy
I1006 11:32:00.011919  3595 net.cpp:430] loss_noisy <- ip2_clean_ip2_clean_0_split_1
I1006 11:32:00.011922  3595 net.cpp:430] loss_noisy <- ip2_ntype_ip2_ntype_0_split_1
I1006 11:32:00.011925  3595 net.cpp:430] loss_noisy <- label_noisy
I1006 11:32:00.011931  3595 net.cpp:388] loss_noisy -> loss_noisy
I1006 11:32:00.011939  3595 net.cpp:140] Setting up loss_noisy
I1006 11:32:00.012022  3595 net.cpp:147] Top shape: (1)
I1006 11:32:00.012028  3595 net.cpp:149]     with loss weight 1
I1006 11:32:00.012035  3595 net.cpp:212] loss_noisy needs backward computation.
I1006 11:32:00.012039  3595 net.cpp:212] loss_ntype needs backward computation.
I1006 11:32:00.012042  3595 net.cpp:212] ip2_ntype_ip2_ntype_0_split needs backward computation.
I1006 11:32:00.012045  3595 net.cpp:212] ip2_ntype needs backward computation.
I1006 11:32:00.012048  3595 net.cpp:212] ip1_ntype needs backward computation.
I1006 11:32:00.012050  3595 net.cpp:212] pool3_ntype needs backward computation.
I1006 11:32:00.012053  3595 net.cpp:212] relu3_ntype needs backward computation.
I1006 11:32:00.012056  3595 net.cpp:212] conv3_ntype needs backward computation.
I1006 11:32:00.012058  3595 net.cpp:212] pool2_ntype needs backward computation.
I1006 11:32:00.012061  3595 net.cpp:212] relu2_ntype needs backward computation.
I1006 11:32:00.012063  3595 net.cpp:212] conv2_ntype needs backward computation.
I1006 11:32:00.012066  3595 net.cpp:212] relu1_ntype needs backward computation.
I1006 11:32:00.012069  3595 net.cpp:212] pool1_ntype needs backward computation.
I1006 11:32:00.012071  3595 net.cpp:212] conv1_ntype needs backward computation.
I1006 11:32:00.012074  3595 net.cpp:212] loss_clean needs backward computation.
I1006 11:32:00.012078  3595 net.cpp:212] ip2_clean_ip2_clean_0_split needs backward computation.
I1006 11:32:00.012080  3595 net.cpp:212] ip2_clean needs backward computation.
I1006 11:32:00.012083  3595 net.cpp:212] ip1_clean needs backward computation.
I1006 11:32:00.012085  3595 net.cpp:212] pool3_clean needs backward computation.
I1006 11:32:00.012089  3595 net.cpp:212] relu3_clean needs backward computation.
I1006 11:32:00.012090  3595 net.cpp:212] conv3_clean needs backward computation.
I1006 11:32:00.012094  3595 net.cpp:212] pool2_clean needs backward computation.
I1006 11:32:00.012095  3595 net.cpp:212] relu2_clean needs backward computation.
I1006 11:32:00.012099  3595 net.cpp:212] conv2_clean needs backward computation.
I1006 11:32:00.012100  3595 net.cpp:212] relu1_clean needs backward computation.
I1006 11:32:00.012104  3595 net.cpp:212] pool1_clean needs backward computation.
I1006 11:32:00.012105  3595 net.cpp:212] conv1_clean needs backward computation.
I1006 11:32:00.012109  3595 net.cpp:214] label_ntype does not need backward computation.
I1006 11:32:00.012111  3595 net.cpp:214] label_noisy does not need backward computation.
I1006 11:32:00.012115  3595 net.cpp:214] label_clean does not need backward computation.
I1006 11:32:00.012116  3595 net.cpp:214] data_cifar_0_split does not need backward computation.
I1006 11:32:00.012120  3595 net.cpp:214] cifar does not need backward computation.
I1006 11:32:00.012122  3595 net.cpp:255] This network produces output loss_clean
I1006 11:32:00.012125  3595 net.cpp:255] This network produces output loss_noisy
I1006 11:32:00.012127  3595 net.cpp:255] This network produces output loss_ntype
I1006 11:32:00.012145  3595 net.cpp:267] Network initialization done.
I1006 11:32:00.012148  3595 net.cpp:268] Memory required for data: 65194412
I1006 11:32:00.012709  3595 solver.cpp:164] Creating test net (#0) specified by net file: models/cifar10_noisy_label_loss_trainval.prototxt
I1006 11:32:00.012748  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1006 11:32:00.012753  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer label_clean
I1006 11:32:00.012755  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer label_noisy
I1006 11:32:00.012758  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer label_ntype
I1006 11:32:00.012768  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer conv1_ntype
I1006 11:32:00.012770  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer pool1_ntype
I1006 11:32:00.012773  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer relu1_ntype
I1006 11:32:00.012774  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer conv2_ntype
I1006 11:32:00.012778  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer relu2_ntype
I1006 11:32:00.012779  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer pool2_ntype
I1006 11:32:00.012781  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer conv3_ntype
I1006 11:32:00.012784  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer relu3_ntype
I1006 11:32:00.012785  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer pool3_ntype
I1006 11:32:00.012789  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer ip1_ntype
I1006 11:32:00.012790  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer ip2_ntype
I1006 11:32:00.012792  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss_ntype
I1006 11:32:00.012794  3595 net.cpp:307] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss_noisy
I1006 11:32:00.012913  3595 net.cpp:46] Initializing net from parameters: 
name: "cifar10_noisy_label_loss"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label_clean"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "external/exp/db/cifar10/cifar10_mean.binaryproto"
  }
  data_param {
    source: "external/exp/db/cifar10/test"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1_clean"
  type: "Convolution"
  bottom: "data"
  top: "conv1_clean"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1_clean"
  type: "Pooling"
  bottom: "conv1_clean"
  top: "pool1_clean"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1_clean"
  type: "ReLU"
  bottom: "pool1_clean"
  top: "pool1_clean"
}
layer {
  name: "conv2_clean"
  type: "Convolution"
  bottom: "pool1_clean"
  top: "conv2_clean"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2_clean"
  type: "ReLU"
  bottom: "conv2_clean"
  top: "conv2_clean"
}
layer {
  name: "pool2_clean"
  type: "Pooling"
  bottom: "conv2_clean"
  top: "pool2_clean"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_clean"
  type: "Convolution"
  bottom: "pool2_clean"
  top: "conv3_clean"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3_clean"
  type: "ReLU"
  bottom: "conv3_clean"
  top: "conv3_clean"
}
layer {
  name: "pool3_clean"
  type: "Pooling"
  bottom: "conv3_clean"
  top: "pool3_clean"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1_clean"
  type: "InnerProduct"
  bottom: "pool3_clean"
  top: "ip1_clean"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip2_clean"
  type: "InnerProduct"
  bottom: "ip1_clean"
  top: "ip2_clean"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2_clean"
  bottom: "label_clean"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss_clean"
  type: "SoftmaxWithLoss"
  bottom: "ip2_clean"
  bottom: "label_clean"
  top: "loss_clean"
  loss_param {
    ignore_label: -1
    normalize: false
  }
}
I1006 11:32:00.012967  3595 layer_factory.hpp:74] Creating layer cifar
I1006 11:32:00.012974  3595 net.cpp:110] Creating Layer cifar
I1006 11:32:00.012979  3595 net.cpp:388] cifar -> data
I1006 11:32:00.012985  3595 net.cpp:388] cifar -> label_clean
I1006 11:32:00.012991  3595 net.cpp:140] Setting up cifar
I1006 11:32:00.012996  3595 data_transformer.cpp:22] Loading mean file from: external/exp/db/cifar10/cifar10_mean.binaryproto
I1006 11:32:00.013066  3595 db_lmdb.cpp:22] Opened lmdb external/exp/db/cifar10/test
I1006 11:32:00.013082  3595 data_layer.cpp:55] Skipping first 0 data points.
I1006 11:32:00.013092  3595 data_layer.cpp:100] output data size: 100,3,32,32
I1006 11:32:00.013134  3595 net.cpp:147] Top shape: 100 3 32 32 (307200)
I1006 11:32:00.013142  3595 net.cpp:147] Top shape: 100 (100)
I1006 11:32:00.013160  3595 layer_factory.hpp:74] Creating layer label_clean_cifar_1_split
I1006 11:32:00.013169  3595 net.cpp:110] Creating Layer label_clean_cifar_1_split
I1006 11:32:00.013175  3595 net.cpp:430] label_clean_cifar_1_split <- label_clean
I1006 11:32:00.013182  3595 net.cpp:388] label_clean_cifar_1_split -> label_clean_cifar_1_split_0
I1006 11:32:00.013202  3595 net.cpp:388] label_clean_cifar_1_split -> label_clean_cifar_1_split_1
I1006 11:32:00.013211  3595 net.cpp:140] Setting up label_clean_cifar_1_split
I1006 11:32:00.013223  3595 net.cpp:147] Top shape: 100 (100)
I1006 11:32:00.013232  3595 net.cpp:147] Top shape: 100 (100)
I1006 11:32:00.013238  3595 layer_factory.hpp:74] Creating layer conv1_clean
I1006 11:32:00.013248  3595 net.cpp:110] Creating Layer conv1_clean
I1006 11:32:00.013257  3595 net.cpp:430] conv1_clean <- data
I1006 11:32:00.013265  3595 net.cpp:388] conv1_clean -> conv1_clean
I1006 11:32:00.013275  3595 net.cpp:140] Setting up conv1_clean
I1006 11:32:00.013890  3595 net.cpp:147] Top shape: 100 32 32 32 (3276800)
I1006 11:32:00.013909  3595 layer_factory.hpp:74] Creating layer pool1_clean
I1006 11:32:00.013923  3595 net.cpp:110] Creating Layer pool1_clean
I1006 11:32:00.013931  3595 net.cpp:430] pool1_clean <- conv1_clean
I1006 11:32:00.013941  3595 net.cpp:388] pool1_clean -> pool1_clean
I1006 11:32:00.013957  3595 net.cpp:140] Setting up pool1_clean
I1006 11:32:00.014183  3595 net.cpp:147] Top shape: 100 32 16 16 (819200)
I1006 11:32:00.014191  3595 layer_factory.hpp:74] Creating layer relu1_clean
I1006 11:32:00.014200  3595 net.cpp:110] Creating Layer relu1_clean
I1006 11:32:00.014206  3595 net.cpp:430] relu1_clean <- pool1_clean
I1006 11:32:00.014216  3595 net.cpp:377] relu1_clean -> pool1_clean (in-place)
I1006 11:32:00.014227  3595 net.cpp:140] Setting up relu1_clean
I1006 11:32:00.014363  3595 net.cpp:147] Top shape: 100 32 16 16 (819200)
I1006 11:32:00.014371  3595 layer_factory.hpp:74] Creating layer conv2_clean
I1006 11:32:00.014380  3595 net.cpp:110] Creating Layer conv2_clean
I1006 11:32:00.014386  3595 net.cpp:430] conv2_clean <- pool1_clean
I1006 11:32:00.014396  3595 net.cpp:388] conv2_clean -> conv2_clean
I1006 11:32:00.014408  3595 net.cpp:140] Setting up conv2_clean
I1006 11:32:00.015215  3595 net.cpp:147] Top shape: 100 32 16 16 (819200)
I1006 11:32:00.015233  3595 layer_factory.hpp:74] Creating layer relu2_clean
I1006 11:32:00.015244  3595 net.cpp:110] Creating Layer relu2_clean
I1006 11:32:00.015252  3595 net.cpp:430] relu2_clean <- conv2_clean
I1006 11:32:00.015260  3595 net.cpp:377] relu2_clean -> conv2_clean (in-place)
I1006 11:32:00.015269  3595 net.cpp:140] Setting up relu2_clean
I1006 11:32:00.015476  3595 net.cpp:147] Top shape: 100 32 16 16 (819200)
I1006 11:32:00.015485  3595 layer_factory.hpp:74] Creating layer pool2_clean
I1006 11:32:00.015494  3595 net.cpp:110] Creating Layer pool2_clean
I1006 11:32:00.015501  3595 net.cpp:430] pool2_clean <- conv2_clean
I1006 11:32:00.015509  3595 net.cpp:388] pool2_clean -> pool2_clean
I1006 11:32:00.015518  3595 net.cpp:140] Setting up pool2_clean
I1006 11:32:00.015646  3595 net.cpp:147] Top shape: 100 32 8 8 (204800)
I1006 11:32:00.015655  3595 layer_factory.hpp:74] Creating layer conv3_clean
I1006 11:32:00.015667  3595 net.cpp:110] Creating Layer conv3_clean
I1006 11:32:00.015676  3595 net.cpp:430] conv3_clean <- pool2_clean
I1006 11:32:00.015684  3595 net.cpp:388] conv3_clean -> conv3_clean
I1006 11:32:00.015698  3595 net.cpp:140] Setting up conv3_clean
I1006 11:32:00.016695  3595 net.cpp:147] Top shape: 100 64 8 8 (409600)
I1006 11:32:00.016711  3595 layer_factory.hpp:74] Creating layer relu3_clean
I1006 11:32:00.016723  3595 net.cpp:110] Creating Layer relu3_clean
I1006 11:32:00.016731  3595 net.cpp:430] relu3_clean <- conv3_clean
I1006 11:32:00.016737  3595 net.cpp:377] relu3_clean -> conv3_clean (in-place)
I1006 11:32:00.016746  3595 net.cpp:140] Setting up relu3_clean
I1006 11:32:00.016875  3595 net.cpp:147] Top shape: 100 64 8 8 (409600)
I1006 11:32:00.016882  3595 layer_factory.hpp:74] Creating layer pool3_clean
I1006 11:32:00.016891  3595 net.cpp:110] Creating Layer pool3_clean
I1006 11:32:00.016896  3595 net.cpp:430] pool3_clean <- conv3_clean
I1006 11:32:00.016906  3595 net.cpp:388] pool3_clean -> pool3_clean
I1006 11:32:00.016916  3595 net.cpp:140] Setting up pool3_clean
I1006 11:32:00.017124  3595 net.cpp:147] Top shape: 100 64 4 4 (102400)
I1006 11:32:00.017132  3595 layer_factory.hpp:74] Creating layer ip1_clean
I1006 11:32:00.017143  3595 net.cpp:110] Creating Layer ip1_clean
I1006 11:32:00.017150  3595 net.cpp:430] ip1_clean <- pool3_clean
I1006 11:32:00.017159  3595 net.cpp:388] ip1_clean -> ip1_clean
I1006 11:32:00.017170  3595 net.cpp:140] Setting up ip1_clean
I1006 11:32:00.017784  3595 net.cpp:147] Top shape: 100 64 (6400)
I1006 11:32:00.017796  3595 layer_factory.hpp:74] Creating layer ip2_clean
I1006 11:32:00.017806  3595 net.cpp:110] Creating Layer ip2_clean
I1006 11:32:00.017813  3595 net.cpp:430] ip2_clean <- ip1_clean
I1006 11:32:00.017823  3595 net.cpp:388] ip2_clean -> ip2_clean
I1006 11:32:00.017834  3595 net.cpp:140] Setting up ip2_clean
I1006 11:32:00.017858  3595 net.cpp:147] Top shape: 100 10 (1000)
I1006 11:32:00.017871  3595 layer_factory.hpp:74] Creating layer ip2_clean_ip2_clean_0_split
I1006 11:32:00.017880  3595 net.cpp:110] Creating Layer ip2_clean_ip2_clean_0_split
I1006 11:32:00.017889  3595 net.cpp:430] ip2_clean_ip2_clean_0_split <- ip2_clean
I1006 11:32:00.017897  3595 net.cpp:388] ip2_clean_ip2_clean_0_split -> ip2_clean_ip2_clean_0_split_0
I1006 11:32:00.017906  3595 net.cpp:388] ip2_clean_ip2_clean_0_split -> ip2_clean_ip2_clean_0_split_1
I1006 11:32:00.017916  3595 net.cpp:140] Setting up ip2_clean_ip2_clean_0_split
I1006 11:32:00.017926  3595 net.cpp:147] Top shape: 100 10 (1000)
I1006 11:32:00.017935  3595 net.cpp:147] Top shape: 100 10 (1000)
I1006 11:32:00.017940  3595 layer_factory.hpp:74] Creating layer accuracy
I1006 11:32:00.017948  3595 net.cpp:110] Creating Layer accuracy
I1006 11:32:00.017956  3595 net.cpp:430] accuracy <- ip2_clean_ip2_clean_0_split_0
I1006 11:32:00.017963  3595 net.cpp:430] accuracy <- label_clean_cifar_1_split_0
I1006 11:32:00.017972  3595 net.cpp:388] accuracy -> accuracy
I1006 11:32:00.017983  3595 net.cpp:140] Setting up accuracy
I1006 11:32:00.017993  3595 net.cpp:147] Top shape: (1)
I1006 11:32:00.018000  3595 layer_factory.hpp:74] Creating layer loss_clean
I1006 11:32:00.018008  3595 net.cpp:110] Creating Layer loss_clean
I1006 11:32:00.018014  3595 net.cpp:430] loss_clean <- ip2_clean_ip2_clean_0_split_1
I1006 11:32:00.018021  3595 net.cpp:430] loss_clean <- label_clean_cifar_1_split_1
I1006 11:32:00.018031  3595 net.cpp:388] loss_clean -> loss_clean
I1006 11:32:00.018041  3595 net.cpp:140] Setting up loss_clean
I1006 11:32:00.018049  3595 layer_factory.hpp:74] Creating layer loss_clean
I1006 11:32:00.018200  3595 net.cpp:147] Top shape: (1)
I1006 11:32:00.018208  3595 net.cpp:149]     with loss weight 1
I1006 11:32:00.018232  3595 net.cpp:212] loss_clean needs backward computation.
I1006 11:32:00.018239  3595 net.cpp:214] accuracy does not need backward computation.
I1006 11:32:00.018245  3595 net.cpp:212] ip2_clean_ip2_clean_0_split needs backward computation.
I1006 11:32:00.018250  3595 net.cpp:212] ip2_clean needs backward computation.
I1006 11:32:00.018255  3595 net.cpp:212] ip1_clean needs backward computation.
I1006 11:32:00.018273  3595 net.cpp:212] pool3_clean needs backward computation.
I1006 11:32:00.018285  3595 net.cpp:212] relu3_clean needs backward computation.
I1006 11:32:00.018290  3595 net.cpp:212] conv3_clean needs backward computation.
I1006 11:32:00.018308  3595 net.cpp:212] pool2_clean needs backward computation.
I1006 11:32:00.018313  3595 net.cpp:212] relu2_clean needs backward computation.
I1006 11:32:00.018318  3595 net.cpp:212] conv2_clean needs backward computation.
I1006 11:32:00.018324  3595 net.cpp:212] relu1_clean needs backward computation.
I1006 11:32:00.018329  3595 net.cpp:212] pool1_clean needs backward computation.
I1006 11:32:00.018334  3595 net.cpp:212] conv1_clean needs backward computation.
I1006 11:32:00.018340  3595 net.cpp:214] label_clean_cifar_1_split does not need backward computation.
I1006 11:32:00.018347  3595 net.cpp:214] cifar does not need backward computation.
I1006 11:32:00.018352  3595 net.cpp:255] This network produces output accuracy
I1006 11:32:00.018357  3595 net.cpp:255] This network produces output loss_clean
I1006 11:32:00.018373  3595 net.cpp:267] Network initialization done.
I1006 11:32:00.018379  3595 net.cpp:268] Memory required for data: 31987608
I1006 11:32:00.018463  3595 solver.cpp:47] Solver scaffolding done.
I1006 11:32:00.018513  3595 caffe.cpp:110] Finetuning from external/exp/models/cifar10_noisy_label_loss_iter_0.caffemodel
I1006 11:32:00.019711  3595 solver.cpp:250] Solving cifar10_noisy_label_loss
I1006 11:32:00.019723  3595 solver.cpp:251] Learning Rate Policy: step
I1006 11:32:00.020400  3595 solver.cpp:293] Iteration 0, Testing net (#0)
I1006 11:32:00.356745  3595 solver.cpp:342]     Test net output #0: accuracy = 0.6297
I1006 11:32:00.356775  3595 solver.cpp:342]     Test net output #1: loss_clean = 2.23482 (* 1 = 2.23482 loss)
I1006 11:32:00.372728  3595 solver.cpp:212] Iteration 0, loss = 2.26519
I1006 11:32:00.372755  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.00922331 (* 1 = 0.00922331 loss)
I1006 11:32:00.372766  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.68418 (* 1 = 1.68418 loss)
I1006 11:32:00.372777  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.571781 (* 1 = 0.571781 loss)
I1006 11:32:00.372793  3595 solver.cpp:507] Iteration 0, lr = 0.001
I1006 11:32:02.308295  3595 solver.cpp:212] Iteration 100, loss = 2.7304
I1006 11:32:02.308341  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0320668 (* 1 = 0.0320668 loss)
I1006 11:32:02.308352  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.99563 (* 1 = 1.99563 loss)
I1006 11:32:02.308363  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.549565 (* 1 = 0.549565 loss)
I1006 11:32:02.308370  3595 solver.cpp:507] Iteration 100, lr = 0.001
I1006 11:32:04.250216  3595 solver.cpp:212] Iteration 200, loss = 2.74518
I1006 11:32:04.250247  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0341087 (* 1 = 0.0341087 loss)
I1006 11:32:04.250259  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.84093 (* 1 = 1.84093 loss)
I1006 11:32:04.250272  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.858722 (* 1 = 0.858722 loss)
I1006 11:32:04.250279  3595 solver.cpp:507] Iteration 200, lr = 0.001
I1006 11:32:06.194759  3595 solver.cpp:212] Iteration 300, loss = 2.72723
I1006 11:32:06.194792  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0611589 (* 1 = 0.0611589 loss)
I1006 11:32:06.194807  3595 solver.cpp:229]     Train net output #1: loss_noisy = 2.0321 (* 1 = 2.0321 loss)
I1006 11:32:06.194818  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.837714 (* 1 = 0.837714 loss)
I1006 11:32:06.194825  3595 solver.cpp:507] Iteration 300, lr = 0.001
I1006 11:32:08.143782  3595 solver.cpp:212] Iteration 400, loss = 2.74654
I1006 11:32:08.143813  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0586397 (* 1 = 0.0586397 loss)
I1006 11:32:08.143837  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.92804 (* 1 = 1.92804 loss)
I1006 11:32:08.143848  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.846706 (* 1 = 0.846706 loss)
I1006 11:32:08.143856  3595 solver.cpp:507] Iteration 400, lr = 0.001
I1006 11:32:10.080405  3595 solver.cpp:293] Iteration 500, Testing net (#0)
I1006 11:32:10.386384  3595 solver.cpp:342]     Test net output #0: accuracy = 0.6429
I1006 11:32:10.386415  3595 solver.cpp:342]     Test net output #1: loss_clean = 1.24925 (* 1 = 1.24925 loss)
I1006 11:32:10.399431  3595 solver.cpp:212] Iteration 500, loss = 2.71415
I1006 11:32:10.399452  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0676958 (* 1 = 0.0676958 loss)
I1006 11:32:10.399466  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.68641 (* 1 = 1.68641 loss)
I1006 11:32:10.399477  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.572441 (* 1 = 0.572441 loss)
I1006 11:32:10.399485  3595 solver.cpp:507] Iteration 500, lr = 0.001
I1006 11:32:12.350273  3595 solver.cpp:212] Iteration 600, loss = 2.60457
I1006 11:32:12.350304  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.029235 (* 1 = 0.029235 loss)
I1006 11:32:12.350329  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.77068 (* 1 = 1.77068 loss)
I1006 11:32:12.350353  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.453681 (* 1 = 0.453681 loss)
I1006 11:32:12.350360  3595 solver.cpp:507] Iteration 600, lr = 0.001
I1006 11:32:14.302654  3595 solver.cpp:212] Iteration 700, loss = 2.58273
I1006 11:32:14.302685  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0406306 (* 1 = 0.0406306 loss)
I1006 11:32:14.302697  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.82502 (* 1 = 1.82502 loss)
I1006 11:32:14.302707  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.837757 (* 1 = 0.837757 loss)
I1006 11:32:14.302714  3595 solver.cpp:507] Iteration 700, lr = 0.001
I1006 11:32:16.253790  3595 solver.cpp:212] Iteration 800, loss = 2.58
I1006 11:32:16.253823  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0759494 (* 1 = 0.0759494 loss)
I1006 11:32:16.253835  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.99969 (* 1 = 1.99969 loss)
I1006 11:32:16.253845  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.819096 (* 1 = 0.819096 loss)
I1006 11:32:16.253852  3595 solver.cpp:507] Iteration 800, lr = 0.001
I1006 11:32:18.205153  3595 solver.cpp:212] Iteration 900, loss = 2.60555
I1006 11:32:18.205186  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0489481 (* 1 = 0.0489481 loss)
I1006 11:32:18.205211  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.79748 (* 1 = 1.79748 loss)
I1006 11:32:18.205221  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.776127 (* 1 = 0.776127 loss)
I1006 11:32:18.205230  3595 solver.cpp:507] Iteration 900, lr = 0.001
I1006 11:32:20.142001  3595 solver.cpp:293] Iteration 1000, Testing net (#0)
I1006 11:32:20.447837  3595 solver.cpp:342]     Test net output #0: accuracy = 0.6612
I1006 11:32:20.447868  3595 solver.cpp:342]     Test net output #1: loss_clean = 1.16079 (* 1 = 1.16079 loss)
I1006 11:32:20.460877  3595 solver.cpp:212] Iteration 1000, loss = 2.5976
I1006 11:32:20.460896  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0473477 (* 1 = 0.0473477 loss)
I1006 11:32:20.460908  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.59952 (* 1 = 1.59952 loss)
I1006 11:32:20.460925  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.532692 (* 1 = 0.532692 loss)
I1006 11:32:20.460937  3595 solver.cpp:507] Iteration 1000, lr = 0.001
I1006 11:32:22.414479  3595 solver.cpp:212] Iteration 1100, loss = 2.50708
I1006 11:32:22.414510  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0233939 (* 1 = 0.0233939 loss)
I1006 11:32:22.414523  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.75362 (* 1 = 1.75362 loss)
I1006 11:32:22.414533  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.433848 (* 1 = 0.433848 loss)
I1006 11:32:22.414541  3595 solver.cpp:507] Iteration 1100, lr = 0.001
I1006 11:32:24.365257  3595 solver.cpp:212] Iteration 1200, loss = 2.49094
I1006 11:32:24.365288  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0360558 (* 1 = 0.0360558 loss)
I1006 11:32:24.365301  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.7802 (* 1 = 1.7802 loss)
I1006 11:32:24.365313  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.782717 (* 1 = 0.782717 loss)
I1006 11:32:24.365319  3595 solver.cpp:507] Iteration 1200, lr = 0.001
I1006 11:32:26.316406  3595 solver.cpp:212] Iteration 1300, loss = 2.48894
I1006 11:32:26.316437  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0650123 (* 1 = 0.0650123 loss)
I1006 11:32:26.316462  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.91283 (* 1 = 1.91283 loss)
I1006 11:32:26.316472  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.799446 (* 1 = 0.799446 loss)
I1006 11:32:26.316479  3595 solver.cpp:507] Iteration 1300, lr = 0.001
I1006 11:32:28.274330  3595 solver.cpp:212] Iteration 1400, loss = 2.52711
I1006 11:32:28.274363  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0299506 (* 1 = 0.0299506 loss)
I1006 11:32:28.274376  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.72991 (* 1 = 1.72991 loss)
I1006 11:32:28.274386  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.728063 (* 1 = 0.728063 loss)
I1006 11:32:28.274399  3595 solver.cpp:507] Iteration 1400, lr = 0.001
I1006 11:32:30.222352  3595 solver.cpp:293] Iteration 1500, Testing net (#0)
I1006 11:32:30.528615  3595 solver.cpp:342]     Test net output #0: accuracy = 0.6666
I1006 11:32:30.528645  3595 solver.cpp:342]     Test net output #1: loss_clean = 1.14672 (* 1 = 1.14672 loss)
I1006 11:32:30.541735  3595 solver.cpp:212] Iteration 1500, loss = 2.52118
I1006 11:32:30.541757  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0428442 (* 1 = 0.0428442 loss)
I1006 11:32:30.541770  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.54275 (* 1 = 1.54275 loss)
I1006 11:32:30.541782  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.526977 (* 1 = 0.526977 loss)
I1006 11:32:30.541793  3595 solver.cpp:507] Iteration 1500, lr = 0.001
I1006 11:32:32.505213  3595 solver.cpp:212] Iteration 1600, loss = 2.44693
I1006 11:32:32.505244  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0187422 (* 1 = 0.0187422 loss)
I1006 11:32:32.505257  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.6909 (* 1 = 1.6909 loss)
I1006 11:32:32.505267  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.414597 (* 1 = 0.414597 loss)
I1006 11:32:32.505275  3595 solver.cpp:507] Iteration 1600, lr = 0.001
I1006 11:32:34.471941  3595 solver.cpp:212] Iteration 1700, loss = 2.41873
I1006 11:32:34.471971  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0346799 (* 1 = 0.0346799 loss)
I1006 11:32:34.471984  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.79647 (* 1 = 1.79647 loss)
I1006 11:32:34.471995  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.730804 (* 1 = 0.730804 loss)
I1006 11:32:34.472002  3595 solver.cpp:507] Iteration 1700, lr = 0.001
I1006 11:32:36.438743  3595 solver.cpp:212] Iteration 1800, loss = 2.41387
I1006 11:32:36.438773  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0647882 (* 1 = 0.0647882 loss)
I1006 11:32:36.438786  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.8626 (* 1 = 1.8626 loss)
I1006 11:32:36.438797  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.766121 (* 1 = 0.766121 loss)
I1006 11:32:36.438805  3595 solver.cpp:507] Iteration 1800, lr = 0.001
I1006 11:32:38.405930  3595 solver.cpp:212] Iteration 1900, loss = 2.46134
I1006 11:32:38.405959  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0263071 (* 1 = 0.0263071 loss)
I1006 11:32:38.405972  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.64832 (* 1 = 1.64832 loss)
I1006 11:32:38.405982  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.676792 (* 1 = 0.676792 loss)
I1006 11:32:38.405990  3595 solver.cpp:507] Iteration 1900, lr = 0.001
I1006 11:32:40.358772  3595 solver.cpp:293] Iteration 2000, Testing net (#0)
I1006 11:32:40.665308  3595 solver.cpp:342]     Test net output #0: accuracy = 0.6658
I1006 11:32:40.665339  3595 solver.cpp:342]     Test net output #1: loss_clean = 1.15348 (* 1 = 1.15348 loss)
I1006 11:32:40.678489  3595 solver.cpp:212] Iteration 2000, loss = 2.46045
I1006 11:32:40.678508  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0406588 (* 1 = 0.0406588 loss)
I1006 11:32:40.678521  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.51579 (* 1 = 1.51579 loss)
I1006 11:32:40.678532  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.494533 (* 1 = 0.494533 loss)
I1006 11:32:40.678541  3595 solver.cpp:507] Iteration 2000, lr = 0.001
I1006 11:32:42.647908  3595 solver.cpp:212] Iteration 2100, loss = 2.3967
I1006 11:32:42.647939  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0167583 (* 1 = 0.0167583 loss)
I1006 11:32:42.647951  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.62697 (* 1 = 1.62697 loss)
I1006 11:32:42.647963  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.380579 (* 1 = 0.380579 loss)
I1006 11:32:42.647975  3595 solver.cpp:507] Iteration 2100, lr = 0.001
I1006 11:32:44.724828  3595 solver.cpp:212] Iteration 2200, loss = 2.36036
I1006 11:32:44.724859  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0288009 (* 1 = 0.0288009 loss)
I1006 11:32:44.724872  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.79169 (* 1 = 1.79169 loss)
I1006 11:32:44.724884  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.690114 (* 1 = 0.690114 loss)
I1006 11:32:44.724890  3595 solver.cpp:507] Iteration 2200, lr = 0.001
I1006 11:32:46.903245  3595 solver.cpp:212] Iteration 2300, loss = 2.33864
I1006 11:32:46.903276  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0561481 (* 1 = 0.0561481 loss)
I1006 11:32:46.903288  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.81275 (* 1 = 1.81275 loss)
I1006 11:32:46.903300  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.69001 (* 1 = 0.69001 loss)
I1006 11:32:46.903306  3595 solver.cpp:507] Iteration 2300, lr = 0.001
I1006 11:32:49.115593  3595 solver.cpp:212] Iteration 2400, loss = 2.40418
I1006 11:32:49.115641  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0249723 (* 1 = 0.0249723 loss)
I1006 11:32:49.115666  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.59365 (* 1 = 1.59365 loss)
I1006 11:32:49.115679  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.662801 (* 1 = 0.662801 loss)
I1006 11:32:49.115686  3595 solver.cpp:507] Iteration 2400, lr = 0.001
I1006 11:32:51.316519  3595 solver.cpp:293] Iteration 2500, Testing net (#0)
I1006 11:32:51.655537  3595 solver.cpp:342]     Test net output #0: accuracy = 0.6664
I1006 11:32:51.655567  3595 solver.cpp:342]     Test net output #1: loss_clean = 1.15646 (* 1 = 1.15646 loss)
I1006 11:32:51.670186  3595 solver.cpp:212] Iteration 2500, loss = 2.39796
I1006 11:32:51.670207  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0333003 (* 1 = 0.0333003 loss)
I1006 11:32:51.670220  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.47933 (* 1 = 1.47933 loss)
I1006 11:32:51.670233  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.454485 (* 1 = 0.454485 loss)
I1006 11:32:51.670243  3595 solver.cpp:507] Iteration 2500, lr = 0.001
I1006 11:32:53.937970  3595 solver.cpp:212] Iteration 2600, loss = 2.34529
I1006 11:32:53.938002  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0170634 (* 1 = 0.0170634 loss)
I1006 11:32:53.938015  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.55064 (* 1 = 1.55064 loss)
I1006 11:32:53.938025  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.333124 (* 1 = 0.333124 loss)
I1006 11:32:53.938032  3595 solver.cpp:507] Iteration 2600, lr = 0.001
I1006 11:32:56.211135  3595 solver.cpp:212] Iteration 2700, loss = 2.31054
I1006 11:32:56.211169  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0295252 (* 1 = 0.0295252 loss)
I1006 11:32:56.211180  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.75214 (* 1 = 1.75214 loss)
I1006 11:32:56.211191  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.652274 (* 1 = 0.652274 loss)
I1006 11:32:56.211199  3595 solver.cpp:507] Iteration 2700, lr = 0.001
I1006 11:32:58.492157  3595 solver.cpp:212] Iteration 2800, loss = 2.26372
I1006 11:32:58.492199  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0551847 (* 1 = 0.0551847 loss)
I1006 11:32:58.492213  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.79882 (* 1 = 1.79882 loss)
I1006 11:32:58.492223  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.646176 (* 1 = 0.646176 loss)
I1006 11:32:58.492233  3595 solver.cpp:507] Iteration 2800, lr = 0.001
I1006 11:33:00.792541  3595 solver.cpp:212] Iteration 2900, loss = 2.3473
I1006 11:33:00.792577  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0246841 (* 1 = 0.0246841 loss)
I1006 11:33:00.792583  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.51909 (* 1 = 1.51909 loss)
I1006 11:33:00.792589  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.633847 (* 1 = 0.633847 loss)
I1006 11:33:00.792606  3595 solver.cpp:507] Iteration 2900, lr = 0.001
I1006 11:33:03.078925  3595 solver.cpp:293] Iteration 3000, Testing net (#0)
I1006 11:33:03.439007  3595 solver.cpp:342]     Test net output #0: accuracy = 0.663
I1006 11:33:03.439041  3595 solver.cpp:342]     Test net output #1: loss_clean = 1.17975 (* 1 = 1.17975 loss)
I1006 11:33:03.454118  3595 solver.cpp:212] Iteration 3000, loss = 2.34158
I1006 11:33:03.454159  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0267083 (* 1 = 0.0267083 loss)
I1006 11:33:03.454171  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.4593 (* 1 = 1.4593 loss)
I1006 11:33:03.454181  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.46595 (* 1 = 0.46595 loss)
I1006 11:33:03.454190  3595 solver.cpp:507] Iteration 3000, lr = 0.001
I1006 11:33:05.739027  3595 solver.cpp:212] Iteration 3100, loss = 2.30743
I1006 11:33:05.739060  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0200619 (* 1 = 0.0200619 loss)
I1006 11:33:05.739073  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.50168 (* 1 = 1.50168 loss)
I1006 11:33:05.739087  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.34315 (* 1 = 0.34315 loss)
I1006 11:33:05.739094  3595 solver.cpp:507] Iteration 3100, lr = 0.001
I1006 11:33:08.042920  3595 solver.cpp:212] Iteration 3200, loss = 2.25377
I1006 11:33:08.042949  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0215546 (* 1 = 0.0215546 loss)
I1006 11:33:08.042958  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.73022 (* 1 = 1.73022 loss)
I1006 11:33:08.042963  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.583215 (* 1 = 0.583215 loss)
I1006 11:33:08.042980  3595 solver.cpp:507] Iteration 3200, lr = 0.001
I1006 11:33:10.345659  3595 solver.cpp:212] Iteration 3300, loss = 2.19569
I1006 11:33:10.345692  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0566655 (* 1 = 0.0566655 loss)
I1006 11:33:10.345701  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.7877 (* 1 = 1.7877 loss)
I1006 11:33:10.345707  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.622277 (* 1 = 0.622277 loss)
I1006 11:33:10.345715  3595 solver.cpp:507] Iteration 3300, lr = 0.001
I1006 11:33:12.628649  3595 solver.cpp:212] Iteration 3400, loss = 2.28889
I1006 11:33:12.628676  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0191218 (* 1 = 0.0191218 loss)
I1006 11:33:12.628684  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.481 (* 1 = 1.481 loss)
I1006 11:33:12.628690  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.548631 (* 1 = 0.548631 loss)
I1006 11:33:12.628693  3595 solver.cpp:507] Iteration 3400, lr = 0.001
I1006 11:33:14.892810  3595 solver.cpp:293] Iteration 3500, Testing net (#0)
I1006 11:33:15.242660  3595 solver.cpp:342]     Test net output #0: accuracy = 0.6531
I1006 11:33:15.242687  3595 solver.cpp:342]     Test net output #1: loss_clean = 1.22416 (* 1 = 1.22416 loss)
I1006 11:33:15.257657  3595 solver.cpp:212] Iteration 3500, loss = 2.29638
I1006 11:33:15.257678  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.025172 (* 1 = 0.025172 loss)
I1006 11:33:15.257684  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.42549 (* 1 = 1.42549 loss)
I1006 11:33:15.257689  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.458052 (* 1 = 0.458052 loss)
I1006 11:33:15.257694  3595 solver.cpp:507] Iteration 3500, lr = 0.001
I1006 11:33:17.534610  3595 solver.cpp:212] Iteration 3600, loss = 2.26394
I1006 11:33:17.534637  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0249197 (* 1 = 0.0249197 loss)
I1006 11:33:17.534643  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.51075 (* 1 = 1.51075 loss)
I1006 11:33:17.534649  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.342782 (* 1 = 0.342782 loss)
I1006 11:33:17.534653  3595 solver.cpp:507] Iteration 3600, lr = 0.001
I1006 11:33:19.817314  3595 solver.cpp:212] Iteration 3700, loss = 2.20761
I1006 11:33:19.817365  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0230709 (* 1 = 0.0230709 loss)
I1006 11:33:19.817373  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.71927 (* 1 = 1.71927 loss)
I1006 11:33:19.817379  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.614776 (* 1 = 0.614776 loss)
I1006 11:33:19.817385  3595 solver.cpp:507] Iteration 3700, lr = 0.001
I1006 11:33:22.098546  3595 solver.cpp:212] Iteration 3800, loss = 2.13993
I1006 11:33:22.098575  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0563184 (* 1 = 0.0563184 loss)
I1006 11:33:22.098582  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.78081 (* 1 = 1.78081 loss)
I1006 11:33:22.098587  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.514175 (* 1 = 0.514175 loss)
I1006 11:33:22.098592  3595 solver.cpp:507] Iteration 3800, lr = 0.001
I1006 11:33:24.372284  3595 solver.cpp:212] Iteration 3900, loss = 2.22297
I1006 11:33:24.372311  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0196696 (* 1 = 0.0196696 loss)
I1006 11:33:24.372318  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.45519 (* 1 = 1.45519 loss)
I1006 11:33:24.372336  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.461971 (* 1 = 0.461971 loss)
I1006 11:33:24.372341  3595 solver.cpp:507] Iteration 3900, lr = 0.001
I1006 11:33:26.630693  3595 solver.cpp:293] Iteration 4000, Testing net (#0)
I1006 11:33:26.979475  3595 solver.cpp:342]     Test net output #0: accuracy = 0.6563
I1006 11:33:26.979501  3595 solver.cpp:342]     Test net output #1: loss_clean = 1.24518 (* 1 = 1.24518 loss)
I1006 11:33:26.994423  3595 solver.cpp:212] Iteration 4000, loss = 2.23614
I1006 11:33:26.994451  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0209375 (* 1 = 0.0209375 loss)
I1006 11:33:26.994458  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.34881 (* 1 = 1.34881 loss)
I1006 11:33:26.994464  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.479689 (* 1 = 0.479689 loss)
I1006 11:33:26.994469  3595 solver.cpp:507] Iteration 4000, lr = 0.0001
I1006 11:33:29.266216  3595 solver.cpp:212] Iteration 4100, loss = 2.3105
I1006 11:33:29.266243  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0104813 (* 1 = 0.0104813 loss)
I1006 11:33:29.266249  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.4903 (* 1 = 1.4903 loss)
I1006 11:33:29.266255  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.359784 (* 1 = 0.359784 loss)
I1006 11:33:29.266259  3595 solver.cpp:507] Iteration 4100, lr = 0.0001
I1006 11:33:31.539419  3595 solver.cpp:212] Iteration 4200, loss = 2.22046
I1006 11:33:31.539448  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0208222 (* 1 = 0.0208222 loss)
I1006 11:33:31.539453  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.65523 (* 1 = 1.65523 loss)
I1006 11:33:31.539459  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.755236 (* 1 = 0.755236 loss)
I1006 11:33:31.539463  3595 solver.cpp:507] Iteration 4200, lr = 0.0001
I1006 11:33:33.812124  3595 solver.cpp:212] Iteration 4300, loss = 2.14545
I1006 11:33:33.812152  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0413353 (* 1 = 0.0413353 loss)
I1006 11:33:33.812160  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.67556 (* 1 = 1.67556 loss)
I1006 11:33:33.812165  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.560598 (* 1 = 0.560598 loss)
I1006 11:33:33.812168  3595 solver.cpp:507] Iteration 4300, lr = 0.0001
I1006 11:33:36.083688  3595 solver.cpp:212] Iteration 4400, loss = 2.10179
I1006 11:33:36.083715  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0143065 (* 1 = 0.0143065 loss)
I1006 11:33:36.083722  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.35769 (* 1 = 1.35769 loss)
I1006 11:33:36.083729  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.622199 (* 1 = 0.622199 loss)
I1006 11:33:36.083732  3595 solver.cpp:507] Iteration 4400, lr = 0.0001
I1006 11:33:38.341177  3595 solver.cpp:293] Iteration 4500, Testing net (#0)
I1006 11:33:38.688521  3595 solver.cpp:342]     Test net output #0: accuracy = 0.6906
I1006 11:33:38.688549  3595 solver.cpp:342]     Test net output #1: loss_clean = 1.07316 (* 1 = 1.07316 loss)
I1006 11:33:38.703583  3595 solver.cpp:212] Iteration 4500, loss = 2.04608
I1006 11:33:38.703603  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0272542 (* 1 = 0.0272542 loss)
I1006 11:33:38.703609  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.43955 (* 1 = 1.43955 loss)
I1006 11:33:38.703614  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.419159 (* 1 = 0.419159 loss)
I1006 11:33:38.703620  3595 solver.cpp:507] Iteration 4500, lr = 0.0001
I1006 11:33:40.979461  3595 solver.cpp:212] Iteration 4600, loss = 2.16182
I1006 11:33:40.979493  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.010225 (* 1 = 0.010225 loss)
I1006 11:33:40.979506  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.41069 (* 1 = 1.41069 loss)
I1006 11:33:40.979532  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.296708 (* 1 = 0.296708 loss)
I1006 11:33:40.979540  3595 solver.cpp:507] Iteration 4600, lr = 0.0001
I1006 11:33:43.256834  3595 solver.cpp:212] Iteration 4700, loss = 2.08756
I1006 11:33:43.256862  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0171466 (* 1 = 0.0171466 loss)
I1006 11:33:43.256870  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.64962 (* 1 = 1.64962 loss)
I1006 11:33:43.256875  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.616391 (* 1 = 0.616391 loss)
I1006 11:33:43.256880  3595 solver.cpp:507] Iteration 4700, lr = 0.0001
I1006 11:33:45.531903  3595 solver.cpp:212] Iteration 4800, loss = 2.02453
I1006 11:33:45.531931  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0399868 (* 1 = 0.0399868 loss)
I1006 11:33:45.531939  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.64687 (* 1 = 1.64687 loss)
I1006 11:33:45.531944  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.50466 (* 1 = 0.50466 loss)
I1006 11:33:45.531960  3595 solver.cpp:507] Iteration 4800, lr = 0.0001
I1006 11:33:47.806303  3595 solver.cpp:212] Iteration 4900, loss = 2.02955
I1006 11:33:47.806330  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0119887 (* 1 = 0.0119887 loss)
I1006 11:33:47.806337  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.32409 (* 1 = 1.32409 loss)
I1006 11:33:47.806342  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.600305 (* 1 = 0.600305 loss)
I1006 11:33:47.806347  3595 solver.cpp:507] Iteration 4900, lr = 0.0001
I1006 11:33:50.066386  3595 solver.cpp:293] Iteration 5000, Testing net (#0)
I1006 11:33:50.413457  3595 solver.cpp:342]     Test net output #0: accuracy = 0.6898
I1006 11:33:50.413486  3595 solver.cpp:342]     Test net output #1: loss_clean = 1.07435 (* 1 = 1.07435 loss)
I1006 11:33:50.428519  3595 solver.cpp:212] Iteration 5000, loss = 2.01857
I1006 11:33:50.428537  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0283765 (* 1 = 0.0283765 loss)
I1006 11:33:50.428544  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.45199 (* 1 = 1.45199 loss)
I1006 11:33:50.428550  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.422059 (* 1 = 0.422059 loss)
I1006 11:33:50.428555  3595 solver.cpp:507] Iteration 5000, lr = 0.0001
I1006 11:33:52.704344  3595 solver.cpp:212] Iteration 5100, loss = 2.12017
I1006 11:33:52.704372  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.00994976 (* 1 = 0.00994976 loss)
I1006 11:33:52.704380  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.39173 (* 1 = 1.39173 loss)
I1006 11:33:52.704385  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.27823 (* 1 = 0.27823 loss)
I1006 11:33:52.704388  3595 solver.cpp:507] Iteration 5100, lr = 0.0001
I1006 11:33:54.978759  3595 solver.cpp:212] Iteration 5200, loss = 2.03915
I1006 11:33:54.978798  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0155122 (* 1 = 0.0155122 loss)
I1006 11:33:54.978806  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.65292 (* 1 = 1.65292 loss)
I1006 11:33:54.978811  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.577587 (* 1 = 0.577587 loss)
I1006 11:33:54.978816  3595 solver.cpp:507] Iteration 5200, lr = 0.0001
I1006 11:33:57.252009  3595 solver.cpp:212] Iteration 5300, loss = 1.96872
I1006 11:33:57.252038  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0383361 (* 1 = 0.0383361 loss)
I1006 11:33:57.252045  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.62307 (* 1 = 1.62307 loss)
I1006 11:33:57.252050  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.475951 (* 1 = 0.475951 loss)
I1006 11:33:57.252055  3595 solver.cpp:507] Iteration 5300, lr = 0.0001
I1006 11:33:59.526832  3595 solver.cpp:212] Iteration 5400, loss = 1.99138
I1006 11:33:59.526859  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0110817 (* 1 = 0.0110817 loss)
I1006 11:33:59.526866  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.30646 (* 1 = 1.30646 loss)
I1006 11:33:59.526871  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.563675 (* 1 = 0.563675 loss)
I1006 11:33:59.526876  3595 solver.cpp:507] Iteration 5400, lr = 0.0001
I1006 11:34:01.785995  3595 solver.cpp:293] Iteration 5500, Testing net (#0)
I1006 11:34:02.132647  3595 solver.cpp:342]     Test net output #0: accuracy = 0.6891
I1006 11:34:02.132674  3595 solver.cpp:342]     Test net output #1: loss_clean = 1.07788 (* 1 = 1.07788 loss)
I1006 11:34:02.147616  3595 solver.cpp:212] Iteration 5500, loss = 1.99468
I1006 11:34:02.147650  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0285343 (* 1 = 0.0285343 loss)
I1006 11:34:02.147658  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.44729 (* 1 = 1.44729 loss)
I1006 11:34:02.147663  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.408067 (* 1 = 0.408067 loss)
I1006 11:34:02.147670  3595 solver.cpp:507] Iteration 5500, lr = 0.0001
I1006 11:34:04.419132  3595 solver.cpp:212] Iteration 5600, loss = 2.08669
I1006 11:34:04.419173  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.00951184 (* 1 = 0.00951184 loss)
I1006 11:34:04.419180  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.37747 (* 1 = 1.37747 loss)
I1006 11:34:04.419186  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.265242 (* 1 = 0.265242 loss)
I1006 11:34:04.419191  3595 solver.cpp:507] Iteration 5600, lr = 0.0001
I1006 11:34:06.691818  3595 solver.cpp:212] Iteration 5700, loss = 2.00416
I1006 11:34:06.691845  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0147431 (* 1 = 0.0147431 loss)
I1006 11:34:06.691853  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.64937 (* 1 = 1.64937 loss)
I1006 11:34:06.691858  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.554451 (* 1 = 0.554451 loss)
I1006 11:34:06.691862  3595 solver.cpp:507] Iteration 5700, lr = 0.0001
I1006 11:34:08.962684  3595 solver.cpp:212] Iteration 5800, loss = 1.92696
I1006 11:34:08.962724  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0373778 (* 1 = 0.0373778 loss)
I1006 11:34:08.962731  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.60558 (* 1 = 1.60558 loss)
I1006 11:34:08.962738  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.452306 (* 1 = 0.452306 loss)
I1006 11:34:08.962743  3595 solver.cpp:507] Iteration 5800, lr = 0.0001
I1006 11:34:11.234274  3595 solver.cpp:212] Iteration 5900, loss = 1.96008
I1006 11:34:11.234303  3595 solver.cpp:229]     Train net output #0: loss_clean = 0.0109167 (* 1 = 0.0109167 loss)
I1006 11:34:11.234310  3595 solver.cpp:229]     Train net output #1: loss_noisy = 1.29583 (* 1 = 1.29583 loss)
I1006 11:34:11.234315  3595 solver.cpp:229]     Train net output #2: loss_ntype = 0.532542 (* 1 = 0.532542 loss)
I1006 11:34:11.234320  3595 solver.cpp:507] Iteration 5900, lr = 0.0001
I1006 11:34:13.492408  3595 solver.cpp:379] Snapshotting to binary proto file external/exp/models/cifar10_noisy_label_loss_iter_6000.caffemodel
I1006 11:34:13.496248  3595 solver.cpp:689] Snapshotting solver state to binary proto fileexternal/exp/models/cifar10_noisy_label_loss_iter_6000.solverstate
I1006 11:34:13.505147  3595 solver.cpp:276] Iteration 6000, loss = 1.86459
I1006 11:34:13.505164  3595 solver.cpp:293] Iteration 6000, Testing net (#0)
I1006 11:34:13.850775  3595 solver.cpp:342]     Test net output #0: accuracy = 0.6897
I1006 11:34:13.850803  3595 solver.cpp:342]     Test net output #1: loss_clean = 1.082 (* 1 = 1.082 loss)
I1006 11:34:13.850808  3595 solver.cpp:281] Optimization Done.
I1006 11:34:13.850811  3595 caffe.cpp:178] Optimization Done.
